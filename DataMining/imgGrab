#!/bin/bash

#This script takes one or more URLs as arguments
#It loops through these URLs grabbing the HTML source,
#    parsing this source for img tags,
#    grabbing the source URL
#    and then downloading any images from these URLs.
#These image files are placed in a direcetory with the name of the URL
#    minus http://www and any other . / or :
#Next all but the largest image is deleted
#    this image is renamed to cover.jpg (or cover.jpeg, cover.png, etc...)

for var in "$@"
do
  f=`echo $var | \
    sed 's_http:__g' | sed 's_//www.__g' | \
    sed 's_[/.:]__g'`

  java URLConnectionReader $var | \
  sed 's_img_\n&_g' | grep "^img" | \
  sed 's_src[\s]*=[\s]*"_\n&_g' | \
  grep "^src" | \
  sed 's_src[\s]*=[\s]*"[\s]*__g' | \
  sed 's_\s_\n~_g' | \
  grep "^http" | \
  sed 's_"_\n"_g' | \
  grep "^http" | \
  egrep "jpg$|jpeg$|png$|bmp$" | \
  wget -i - -P ./$f -A jpg,jpeg,png,bmp -q -nc
  find ./$f -type f -print0 | xargs -0 du -s | sort -rn | awk 'NR>1 {print $NF}' | xargs rm -f
  if ls -U ./$f/*.jpg > /dev/null 2>&1
  then
    mv ./$f/*.jpg ./$f/cover.jpg
  fi
  if ls -U ./$f/*.jpeg > /dev/null 2>&1
  then
    mv ./$f/*.jpeg ./$f/cover.jpeg
  fi
  if ls -U ./$f/*.png > /dev/null 2>&1
  then
    mv ./$f/*.png ./$f/cover.png
  fi
  if ls -U ./$f/*.bmp > /dev/null 2>&1
  then
    mv ./$f/*.bmp ./$f/cover.bmp
  fi
done

